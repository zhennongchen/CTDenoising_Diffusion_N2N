{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "You should prepare the following things before running this step. I also prepare a set of example data in the folder ```example_data```.\n",
    "\n",
    "1. **simulated dataset** \n",
    "   - check step 1\n",
    "   - for example data: we prepare one case ```00004038/0000455420```, under the ```example_data/fixedCT``` is its clean low-noise ground truth, under the ```example_data/simulation``` we have ```gaussian_random_0``` for unsupervised learning and ```poisson_random_0``` for supervised learning.\n",
    "\n",
    "\n",
    "2. **A patient list** that emunarates the dataset \n",
    "   - check step 2\n",
    "   - for example data: we prepare two lists, ```example_data/Patient_lists/patient_list_unsupervised_gaussian.xlsx``` for unsupervised learning (our proposed method) and ```example_data/Patient_lists/patient_list_supervised_poisson.xlsx``` for supervised learning.\n",
    "\n",
    "\n",
    "3. bins for **histogram equalization**\n",
    "    - provided in ```/help_data```\n",
    "\n",
    "---\n",
    "\n",
    "## Task: Train the model\n",
    "\n",
    "- we have two types of noisy data: type 1 (possion) and type 2 (gaussian)\n",
    "- These are the settings of the model:\n",
    "   - **supervised vs. unsupervised**: \n",
    "      - **supervised** represents training on pairs of noisy-free thin-slice and noisy thin-slice with type 1 noise. it will be tested on type 2 noise to evaluate domain shift influence; \n",
    "      - ***unsupervised** is our method based on diffusion+noise2noise and directly trained on type 2 noise.\n",
    "\n",
    "   - **beta**: this is the weight of bias loss. The total loss = diffusion loss + beta * bias loss. currently beta = 0.\n",
    "\n",
    "---\n",
    "\n",
    "### Docker environment\n",
    "Please use `docker/docker_pytorch`, it will build a pytorch docker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/Documents/CTDenoising_Diffusion_N2N/denoising_diffusion_pytorch/denoising_diffusion_pytorch/conditional_diffusion.py:1000: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @autocast(enabled = False)\n"
     ]
    }
   ],
   "source": [
    "import sys \n",
    "sys.path.append('/workspace/Documents')\n",
    "import os\n",
    "import torch\n",
    "import numpy as np \n",
    "import CTDenoising_Diffusion_N2N.denoising_diffusion_pytorch.denoising_diffusion_pytorch.conditional_diffusion as ddpm\n",
    "import CTDenoising_Diffusion_N2N.functions_collection as ff\n",
    "import CTDenoising_Diffusion_N2N.Build_lists.Build_list as Build_list\n",
    "import CTDenoising_Diffusion_N2N.Generator as Generator\n",
    "\n",
    "main_path = '/mnt/camca_NAS/denoising/'  # replace with your own path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 1: define settings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_unsupervised_gaussian_beta0\n"
     ]
    }
   ],
   "source": [
    "supervision = 'unsupervised' # 'unsupervised' or 'supervised'\n",
    "noise_type = 'possion' if supervision == 'supervised' else 'gaussian'\n",
    "beta = 0 # by default\n",
    "\n",
    "trial_name = 'model_'+supervision + '_' + noise_type + '_beta' + str(beta)\n",
    "print(trial_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 2: set default parameters\n",
    "usually you don't need to change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_dimension = '2D'\n",
    "condition_channel = 1 if (supervision == 'supervised') or ('mean' in trial_name) else 2\n",
    "image_size = [512,512]\n",
    "num_patches_per_slice = 2\n",
    "patch_size = [128,128]\n",
    "\n",
    "objective = 'pred_x0'\n",
    "\n",
    "histogram_equalization = True\n",
    "background_cutoff = -1000\n",
    "maximum_cutoff = 2000\n",
    "normalize_factor = 'equation'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 3: define patient list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (1,) (1,) val: (1,) (1,)\n",
      "training condition: /mnt/camca_NAS/denoising/example_data/simulation/00004038/0000455420/gaussian_random_0/recon.nii.gz  x0: /mnt/camca_NAS/denoising/example_data/fixedCT/00004038/0000455420/img_thinslice_partial.nii.gz\n",
      "validation condition: /mnt/camca_NAS/denoising/example_data/simulation/00004038/0000455420/gaussian_random_0/recon.nii.gz  x0: /mnt/camca_NAS/denoising/example_data/fixedCT/00004038/0000455420/img_thinslice_partial.nii.gz\n"
     ]
    }
   ],
   "source": [
    "# define train\n",
    "if supervision == 'supervised':\n",
    "    build_sheet =  Build_list.Build(os.path.join(main_path, 'example_data/Patient_lists','patient_list_supervised_poisson.xlsx'))\n",
    "else:\n",
    "    build_sheet =  Build_list.Build(os.path.join(main_path, 'example_data/Patient_lists','patient_list_unsupervised_gaussian.xlsx'))\n",
    "\n",
    "_,_,_,_, condition_list_train, x0_list_train = build_sheet.__build__(batch_list = [0]) # batch list selects which batch we will use for training. usually you will have several batches and you leave one for validation and another for testing. here for the purpose of example, we use the same data for training and validation. \n",
    "x0_list_train = x0_list_train[0:1]; condition_list_train = condition_list_train[0:1]  \n",
    "\n",
    "# define val\n",
    "_,_,_,_, condition_list_val, x0_list_val = build_sheet.__build__(batch_list = [0])\n",
    "x0_list_val = x0_list_val[0:1]; condition_list_val = condition_list_val[0:1]\n",
    "\n",
    "\n",
    "print('train:', x0_list_train.shape, condition_list_train.shape, 'val:', x0_list_val.shape, condition_list_val.shape)\n",
    "print('training condition:', condition_list_train[0], ' x0:', x0_list_train[0])\n",
    "print('validation condition:', condition_list_val[0], ' x0:', x0_list_val[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 4: define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is ddim sampling True\n"
     ]
    }
   ],
   "source": [
    "# define u-net and diffusion model\n",
    "model = ddpm.Unet(\n",
    "    problem_dimension = problem_dimension,\n",
    "    init_dim = 64,\n",
    "    out_dim = 1,\n",
    "    channels = 1, \n",
    "    conditional_diffusion = True,\n",
    "    condition_channels = condition_channel,\n",
    "\n",
    "    downsample_list = (True, True, True, False), # don't change\n",
    "    upsample_list = (True, True, True, False), # don't change\n",
    "    full_attn = (None, None, False, True),) # if you have enough GPU memory, you can set True to False (meaning you change from full attention to linear attention); then you can further save GPU by setting False to None (remove attention)\n",
    "\n",
    "diffusion_model = ddpm.GaussianDiffusion(\n",
    "    model,\n",
    "    image_size = image_size if num_patches_per_slice == None else patch_size,\n",
    "    timesteps = 1000,\n",
    "    sampling_timesteps = 250,\n",
    "    objective = objective,\n",
    "    clip_or_not =False,\n",
    "    auto_normalize = False,)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 5: define data generator (Training and validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_train = Generator.Dataset_2D(\n",
    "        supervision = supervision,\n",
    "\n",
    "        img_list = x0_list_train,\n",
    "        condition_list = condition_list_train,\n",
    "        image_size = image_size,\n",
    "\n",
    "        num_slices_per_image = 50,\n",
    "        random_pick_slice = True,\n",
    "        slice_range = None,\n",
    "\n",
    "        num_patches_per_slice = num_patches_per_slice,\n",
    "        patch_size = patch_size,\n",
    "\n",
    "        histogram_equalization = histogram_equalization,\n",
    "        bins = np.load('./help_data/histogram_equalization/bins.npy'),\n",
    "        bins_mapped = np.load('./help_data/histogram_equalization/bins_mapped.npy'),\n",
    "\n",
    "        background_cutoff = background_cutoff,\n",
    "        maximum_cutoff = maximum_cutoff,\n",
    "        normalize_factor = normalize_factor,\n",
    "\n",
    "        shuffle = True,\n",
    "        augment = True,\n",
    "        augment_frequency = 0.5,)\n",
    "\n",
    "generator_val = Generator.Dataset_2D(\n",
    "        supervision = supervision,\n",
    "\n",
    "        img_list = x0_list_val,\n",
    "        condition_list = condition_list_val,\n",
    "        image_size = image_size,\n",
    "\n",
    "        num_slices_per_image = 20,\n",
    "        random_pick_slice = False,\n",
    "        slice_range = [50,70],\n",
    "\n",
    "        num_patches_per_slice = 1,\n",
    "        patch_size = [512,512],\n",
    "\n",
    "        histogram_equalization = histogram_equalization,\n",
    "        bins = np.load('./help_data/histogram_equalization/bins.npy'),\n",
    "        bins_mapped = np.load('./help_data/histogram_equalization/bins_mapped.npy'),\n",
    "        \n",
    "        background_cutoff = background_cutoff,\n",
    "        maximum_cutoff = maximum_cutoff,\n",
    "        normalize_factor = normalize_factor,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conditional diffusion:  True\n"
     ]
    }
   ],
   "source": [
    "### define trainer\n",
    "results_folder = os.path.join(main_path, 'models', trial_name, 'models')\n",
    "ff.make_folder([os.path.join(main_path, 'models'), os.path.join(main_path, 'models', trial_name), results_folder, os.path.join(main_path, 'models', trial_name, 'log')])\n",
    "\n",
    "trainer = ddpm.Trainer(\n",
    "    diffusion_model= diffusion_model,\n",
    "    generator_train = generator_train,\n",
    "    generator_val = generator_val,\n",
    "    train_batch_size = 25, # make it small if you have limited GPU memory\n",
    "    \n",
    "    accum_iter = 1,\n",
    "    train_num_steps = 200, # total training epochs\n",
    "    results_folder = os.path.join('/mnt/camca_NAS/denoising/models', trial_name, 'models'),\n",
    "   \n",
    "    train_lr = 1e-4,\n",
    "    train_lr_decay_every = 200, \n",
    "    save_models_every = 1,\n",
    "    validation_every = 1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define pretrained model if any\n",
    "pre_trained_model = None\n",
    "start_step = 0 # define it as 0 if not using pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "trainer.train(pre_trained_model=pre_trained_model, start_step= start_step, beta = beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
