{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "You should prepare the following things before running this step. I also prepare a set of example data in the folder ```example_data```.\n",
    "\n",
    "1. **simulated dataset** \n",
    "   - check step 1\n",
    "   - for example data: we prepare one case ```00004038/0000455420```, under the ```example_data/fixedCT``` is its clean low-noise ground truth, under the ```example_data/simulation``` we have ```gaussian_random_0``` for unsupervised learning and ```poisson_random_0``` for supervised learning.\n",
    "\n",
    "\n",
    "2. **A patient list** that emunarates the dataset \n",
    "   - check step 2\n",
    "   - for example data: we prepare two lists, ```example_data/Patient_lists/patient_list_unsupervised_gaussian.xlsx``` for unsupervised learning (our proposed method) and ```example_data/Patient_lists/patient_list_supervised_poisson.xlsx``` for supervised learning.\n",
    "\n",
    "\n",
    "3. bins for **histogram equalization**\n",
    "    - provided in ```/help_data```\n",
    "\n",
    "---\n",
    "\n",
    "## Task: Train the model\n",
    "\n",
    "- we have two types of noisy data: type 1 (possion) and type 2 (gaussian)\n",
    "- These are the settings of the model:\n",
    "   - **supervised vs. unsupervised**: \n",
    "      - **supervised** represents training on pairs of noisy-free thin-slice and noisy thin-slice with type 1 noise. it will be tested on type 2 noise to evaluate domain shift influence; \n",
    "      - ***unsupervised** is our method based on diffusion+noise2noise and directly trained on type 2 noise.\n",
    "\n",
    "   - **beta**: this is the weight of bias loss. The total loss = diffusion loss + beta * bias loss. currently beta = 0.\n",
    "\n",
    "---\n",
    "\n",
    "### Docker environment\n",
    "Please use `docker/docker_pytorch`, it will build a pytorch docker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys \n",
    "sys.path.append('/host/d/Github/')\n",
    "import os\n",
    "import torch\n",
    "import numpy as np \n",
    "import CTDenoising_Diffusion_N2N.denoising_diffusion_pytorch.denoising_diffusion_pytorch.conditional_diffusion as ddpm\n",
    "import CTDenoising_Diffusion_N2N.functions_collection as ff\n",
    "import CTDenoising_Diffusion_N2N.Build_lists.Build_list as Build_list\n",
    "import CTDenoising_Diffusion_N2N.Generator as Generator\n",
    "\n",
    "main_path = '/host/d/Github/CTDenoising_Diffusion_N2N/'  # replace with your own path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 1: define settings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_supervised_possion_beta0\n"
     ]
    }
   ],
   "source": [
    "supervision = 'supervised' # 'unsupervised' or 'supervised'\n",
    "noise_type = 'possion' if supervision == 'supervised' else 'gaussian'\n",
    "beta = 0 # by default\n",
    "\n",
    "trial_name = 'model_'+supervision + '_' + noise_type + '_beta' + str(beta)\n",
    "print(trial_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 2: set default parameters\n",
    "usually you don't need to change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_dimension = '2D'\n",
    "condition_channel = 1 if (supervision == 'supervised') or ('mean' in trial_name) else 2\n",
    "image_size = [512,512]\n",
    "num_patches_per_slice = 2\n",
    "patch_size = [128,128]\n",
    "\n",
    "objective = 'pred_x0'\n",
    "\n",
    "histogram_equalization = True\n",
    "background_cutoff = -1000\n",
    "maximum_cutoff = 2000\n",
    "normalize_factor = 'equation'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 3: define patient list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (1,) (1,) val: (1,) (1,)\n",
      "training condition: /host/d/Github/CTDenoising_Diffusion_N2N/example_data/simulation/00004038/0000455420/poisson_random_0/recon.nii.gz  x0: /host/d/Github/CTDenoising_Diffusion_N2N/example_data/fixedCT/00004038/0000455420/img_thinslice_partial.nii.gz\n",
      "validation condition: /host/d/Github/CTDenoising_Diffusion_N2N/example_data/simulation/00004038/0000455420/poisson_random_0/recon.nii.gz  x0: /host/d/Github/CTDenoising_Diffusion_N2N/example_data/fixedCT/00004038/0000455420/img_thinslice_partial.nii.gz\n"
     ]
    }
   ],
   "source": [
    "# define train\n",
    "if supervision == 'supervised':\n",
    "    build_sheet =  Build_list.Build(os.path.join(main_path, 'example_data/Patient_lists','patient_list_supervised.xlsx'))\n",
    "else:\n",
    "    build_sheet =  Build_list.Build(os.path.join(main_path, 'example_data/Patient_lists','patient_list_unsupervised_gaussian.xlsx'))\n",
    "\n",
    "_,_,_,_, condition_list_train, x0_list_train = build_sheet.__build__(batch_list = [0]) # batch list selects which batch we will use for training. usually you will have several batches and you leave one for validation and another for testing. here for the purpose of example, we use the same data for training and validation. \n",
    "x0_list_train = x0_list_train[0:1]; condition_list_train = condition_list_train[0:1]  \n",
    "\n",
    "# define val\n",
    "_,_,_,_, condition_list_val, x0_list_val = build_sheet.__build__(batch_list = [0])\n",
    "x0_list_val = x0_list_val[0:1]; condition_list_val = condition_list_val[0:1]\n",
    "\n",
    "\n",
    "print('train:', x0_list_train.shape, condition_list_train.shape, 'val:', x0_list_val.shape, condition_list_val.shape)\n",
    "print('training condition:', condition_list_train[0], ' x0:', x0_list_train[0])\n",
    "print('validation condition:', condition_list_val[0], ' x0:', x0_list_val[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 4: define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is ddim sampling True\n"
     ]
    }
   ],
   "source": [
    "# define u-net and diffusion model\n",
    "model = ddpm.Unet(\n",
    "    problem_dimension = problem_dimension,\n",
    "    init_dim = 64,\n",
    "    out_dim = 1,\n",
    "    channels = 1, \n",
    "    conditional_diffusion = True,\n",
    "    condition_channels = condition_channel,\n",
    "\n",
    "    downsample_list = (True, True, True, False), # don't change\n",
    "    upsample_list = (True, True, True, False), # don't change\n",
    "    full_attn = (None, None, False, True),) # if you have enough GPU memory, you can set True to False (meaning you change from full attention to linear attention); then you can further save GPU by setting False to None (remove attention)\n",
    "\n",
    "diffusion_model = ddpm.GaussianDiffusion(\n",
    "    model,\n",
    "    image_size = image_size if num_patches_per_slice == None else patch_size,\n",
    "    timesteps = 1000,\n",
    "    sampling_timesteps = 250,\n",
    "    objective = objective,\n",
    "    clip_or_not =False,\n",
    "    auto_normalize = False,)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 5: define data generator (Training and validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_train = Generator.Dataset_2D(\n",
    "        supervision = supervision,\n",
    "\n",
    "        img_list = x0_list_train,\n",
    "        condition_list = condition_list_train,\n",
    "        image_size = image_size,\n",
    "\n",
    "        num_slices_per_image = 50,\n",
    "        random_pick_slice = True,\n",
    "        slice_range = None,\n",
    "\n",
    "        num_patches_per_slice = num_patches_per_slice,\n",
    "        patch_size = patch_size,\n",
    "\n",
    "        histogram_equalization = histogram_equalization,\n",
    "        bins = np.load('./help_data/histogram_equalization/bins.npy'),\n",
    "        bins_mapped = np.load('./help_data/histogram_equalization/bins_mapped.npy'),\n",
    "\n",
    "        background_cutoff = background_cutoff,\n",
    "        maximum_cutoff = maximum_cutoff,\n",
    "        normalize_factor = normalize_factor,\n",
    "\n",
    "        shuffle = True,\n",
    "        augment = True,\n",
    "        augment_frequency = 0.5,)\n",
    "\n",
    "generator_val = Generator.Dataset_2D(\n",
    "        supervision = supervision,\n",
    "\n",
    "        img_list = x0_list_val,\n",
    "        condition_list = condition_list_val,\n",
    "        image_size = image_size,\n",
    "\n",
    "        num_slices_per_image = 20,\n",
    "        random_pick_slice = False,\n",
    "        slice_range = [50,70],\n",
    "\n",
    "        num_patches_per_slice = 1,\n",
    "        patch_size = [512,512],\n",
    "\n",
    "        histogram_equalization = histogram_equalization,\n",
    "        bins = np.load('./help_data/histogram_equalization/bins.npy'),\n",
    "        bins_mapped = np.load('./help_data/histogram_equalization/bins_mapped.npy'),\n",
    "        \n",
    "        background_cutoff = background_cutoff,\n",
    "        maximum_cutoff = maximum_cutoff,\n",
    "        normalize_factor = normalize_factor,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conditional diffusion:  True\n"
     ]
    }
   ],
   "source": [
    "### define trainer\n",
    "# define the folder to save models and create folders\n",
    "model_save_folder = os.path.join('/host/d/projects/denoising/models', trial_name, 'models')\n",
    "ff.make_folder([os.path.join('/host/d/projects/denoising/models'), os.path.join('/host/d/projects/denoising/models', trial_name), model_save_folder, os.path.join('/host/d/projects/denoising/models', trial_name, 'log')])\n",
    "\n",
    "trainer = ddpm.Trainer(\n",
    "    diffusion_model= diffusion_model,\n",
    "    generator_train = generator_train,\n",
    "    generator_val = generator_val,\n",
    "    train_batch_size = 25, # make it small if you have limited GPU memory\n",
    "    \n",
    "    accum_iter = 1,\n",
    "    train_num_steps = 200, # total training epochs\n",
    "    results_folder = model_save_folder,\n",
    "   \n",
    "    train_lr = 1e-4,\n",
    "    train_lr_decay_every = 200, \n",
    "    save_models_every = 1,\n",
    "    validation_every = 1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define pretrained model if any\n",
    "pre_trained_model = None\n",
    "start_step = 0 # define it as 0 if not using pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training epoch:  1\n",
      "learning rate:  0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "average loss: 2.5926, diffusion loss: 2.5926, bias loss: 0.1521:   0%|          | 0/200 [00:10<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i am saving model at step:  1\n",
      "model saved\n",
      "validation at step:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "average loss: 2.5926, diffusion loss: 2.5926, bias loss: 0.1521:   0%|          | 1/200 [00:34<1:53:53, 34.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss:  6.469277858734131 validation diffusion loss:  6.469277858734131 validation bias loss:  0.39400869607925415\n",
      "now run on_epoch_end function\n",
      "now run on_epoch_end function\n",
      "training epoch:  2\n",
      "learning rate:  0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "average loss: 0.8388, diffusion loss: 0.8388, bias loss: 0.0768:   0%|          | 1/200 [01:22<1:53:53, 34.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i am saving model at step:  2\n",
      "model saved\n",
      "validation at step:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "average loss: 0.8388, diffusion loss: 0.8388, bias loss: 0.0768:   1%|          | 2/200 [01:58<3:29:14, 63.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss:  0.6383498311042786 validation diffusion loss:  0.6383498311042786 validation bias loss:  0.011363144032657146\n",
      "now run on_epoch_end function\n",
      "now run on_epoch_end function\n",
      "training epoch:  3\n",
      "learning rate:  0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "average loss: 0.8388, diffusion loss: 0.8388, bias loss: 0.0768:   1%|          | 2/200 [02:04<3:25:14, 62.20s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# train\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpre_trained_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_trained_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstart_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/host/d/Github/CTDenoising_Diffusion_N2N/denoising_diffusion_pytorch/denoising_diffusion_pytorch/conditional_diffusion.py:1218\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, pre_trained_model, start_step, beta)\u001b[0m\n\u001b[1;32m   1216\u001b[0m \u001b[38;5;66;03m# bias loss\u001b[39;00m\n\u001b[1;32m   1217\u001b[0m gauss_kernel \u001b[38;5;241m=\u001b[39m kernel\u001b[38;5;241m.\u001b[39mget_gaussian_kernel(kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m37\u001b[39m, sigma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m)\n\u001b[0;32m-> 1218\u001b[0m lowpass_out \u001b[38;5;241m=\u001b[39m \u001b[43mkernel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_lowpass_gaussian\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgauss_kernel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1219\u001b[0m lowpass_target \u001b[38;5;241m=\u001b[39m kernel\u001b[38;5;241m.\u001b[39mapply_lowpass_gaussian(torch\u001b[38;5;241m.\u001b[39mclone(data_x0), gauss_kernel)\n\u001b[1;32m   1221\u001b[0m bias_loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmse_loss(lowpass_out, lowpass_target, reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/host/d/Github/CTDenoising_Diffusion_N2N/denoising_diffusion_pytorch/denoising_diffusion_pytorch/kernel.py:19\u001b[0m, in \u001b[0;36mapply_lowpass_gaussian\u001b[0;34m(img, kernel)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Apply Gaussian filtering to BCHW tensor using depthwise conv.\"\"\"\u001b[39;00m\n\u001b[1;32m     18\u001b[0m B, C, H, W \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m---> 19\u001b[0m kernel \u001b[38;5;241m=\u001b[39m \u001b[43mkernel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m kernel \u001b[38;5;241m=\u001b[39m kernel\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m*\u001b[39mkernel\u001b[38;5;241m.\u001b[39mshape)  \u001b[38;5;66;03m# [1,1,k,k]\u001b[39;00m\n\u001b[1;32m     21\u001b[0m kernel \u001b[38;5;241m=\u001b[39m kernel\u001b[38;5;241m.\u001b[39mrepeat(C, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# [C,1,k,k]\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train\n",
    "trainer.train(pre_trained_model=pre_trained_model, start_step= start_step, beta = beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
