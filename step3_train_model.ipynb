{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "You should prepare the following things before running this step. \n",
    "\n",
    "1. **simulated dataset** \n",
    "   - check step 1\n",
    "\n",
    "2. **A patient list** that emunarates the dataset \n",
    "   - check step 2\n",
    "\n",
    "3. bins for **histogram equalization**\n",
    "    - provided in ```/help_data```\n",
    "\n",
    "---\n",
    "\n",
    "## Task: Train the model\n",
    "\n",
    "- we have two types of noisy data: type 1 (possion) and type 2 (gaussian)\n",
    "- These are the settings of the model:\n",
    "   - **supervised vs. unsupervised**: *supervised* represents training on pairs of noisy-free thin-slice and noisy thin-slice with type 1 noise. it will be tested on type 2 noise to evaluate domain shift influence; *unsupervised* is our method based on noise2noise.\n",
    "\n",
    "   - **current vs. mean**: For our method,  *current* represents the model takes two adjacent slices as condition and targets on the current slice; while *mean* represents the model takes the current slice as condition and targets on the \"mean\" of two adjacent slices; The default is *current*.\n",
    "\n",
    "   - **beta**: this is the weight of bias loss. The total loss = diffusion loss + beta * bias loss.\n",
    "\n",
    "---\n",
    "\n",
    "### Docker environment\n",
    "Please use `docker/docker_pytorch`, it will build a tensorflow docker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/workspace/Documents/CTDenoising_Diffusion_N2N/denoising_diffusion_pytorch/denoising_diffusion_pytorch/conditional_diffusion.py:1000: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @autocast(enabled = False)\n"
     ]
    }
   ],
   "source": [
    "import sys \n",
    "sys.path.append('/workspace/Documents')\n",
    "import os\n",
    "import torch\n",
    "import numpy as np \n",
    "import CTDenoising_Diffusion_N2N.denoising_diffusion_pytorch.denoising_diffusion_pytorch.conditional_diffusion as ddpm\n",
    "import CTDenoising_Diffusion_N2N.functions_collection as ff\n",
    "import CTDenoising_Diffusion_N2N.Build_lists.Build_list as Build_list\n",
    "import CTDenoising_Diffusion_N2N.Generator as Generator\n",
    "\n",
    "main_path = '/mnt/camca_NAS/denoising/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 1: define settings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unsupervised_gaussian_2D_current_beta10\n"
     ]
    }
   ],
   "source": [
    "supervision = 'unsupervised' # 'unsupervised' or 'supervised'\n",
    "noise_type = 'possion' if supervision == 'supervised' else 'gaussian'\n",
    "target = 'current' # 'current' or 'mean', default is current\n",
    "beta = 0\n",
    "\n",
    "trial_name = supervision + '_' + noise_type + '_' + target + '_beta' + str(beta)\n",
    "print(trial_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 2: set default parameters\n",
    "usually you don't need to change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_dimension = '2D'\n",
    "condition_channel = 1 if (supervision == 'supervised') or ('mean' in trial_name) else 2\n",
    "image_size = [512,512]\n",
    "num_patches_per_slice = 2\n",
    "patch_size = [128,128]\n",
    "\n",
    "objective = 'pred_x0'\n",
    "\n",
    "histogram_equalization = True\n",
    "background_cutoff = -1000\n",
    "maximum_cutoff = 2000\n",
    "normalize_factor = 'equation'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 3: define patient list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (1,) (1,) val: (1,) (1,)\n"
     ]
    }
   ],
   "source": [
    "# define train\n",
    "if supervision == 'supervised':\n",
    "    build_sheet =  Build_list.Build(os.path.join(main_path, 'Patient_lists','fixedCT_static_simulation_train_test_possion_local.xlsx'))\n",
    "else:\n",
    "    build_sheet =  Build_list.Build(os.path.join(main_path, 'Patient_lists','fixedCT_static_simulation_train_test_gaussian_local.xlsx'))\n",
    "\n",
    "_,_,_,_, condition_list_train, x0_list_train = build_sheet.__build__(batch_list = [0,1,2,3]) \n",
    "x0_list_train = x0_list_train[0:1]; condition_list_train = condition_list_train[0:1]  \n",
    "\n",
    "# define val\n",
    "_,_,_,_, condition_list_val, x0_list_val = build_sheet.__build__(batch_list = [4])\n",
    "x0_list_val = x0_list_val[0:1]; condition_list_val = condition_list_val[0:1]\n",
    "\n",
    "\n",
    "print('train:', x0_list_train.shape, condition_list_train.shape, 'val:', x0_list_val.shape, condition_list_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 4: define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is ddim sampling True\n"
     ]
    }
   ],
   "source": [
    "# define u-net and diffusion model\n",
    "model = ddpm.Unet(\n",
    "    problem_dimension = problem_dimension,\n",
    "    init_dim = 64,\n",
    "    out_dim = 1,\n",
    "    channels = 1, \n",
    "    conditional_diffusion = True,\n",
    "    condition_channels = condition_channel,\n",
    "\n",
    "    downsample_list = (True, True, True, False),\n",
    "    upsample_list = (True, True, True, False),\n",
    "    full_attn = (None, None, False, True),)\n",
    "\n",
    "\n",
    "diffusion_model = ddpm.GaussianDiffusion(\n",
    "    model,\n",
    "    image_size = image_size if num_patches_per_slice == None else patch_size,\n",
    "    timesteps = 1000,\n",
    "    sampling_timesteps = 250,\n",
    "    objective = objective,\n",
    "    clip_or_not =False,\n",
    "    auto_normalize = False,)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 5: define data generator (Training and validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_train = Generator.Dataset_2D(\n",
    "        supervision = supervision,\n",
    "        target = target,\n",
    "\n",
    "        img_list = x0_list_train,\n",
    "        condition_list = condition_list_train,\n",
    "        image_size = image_size,\n",
    "\n",
    "        num_slices_per_image = 50,\n",
    "        random_pick_slice = True,\n",
    "        slice_range = None,\n",
    "\n",
    "        num_patches_per_slice = num_patches_per_slice,\n",
    "        patch_size = patch_size,\n",
    "\n",
    "        histogram_equalization = histogram_equalization,\n",
    "        bins = np.load('./help_data/histogram_equalization/bins.npy'),\n",
    "        bins_mapped = np.load('./help_data/histogram_equalization/bins_mapped.npy'),\n",
    "\n",
    "        background_cutoff = background_cutoff,\n",
    "        maximum_cutoff = maximum_cutoff,\n",
    "        normalize_factor = normalize_factor,\n",
    "\n",
    "        shuffle = True,\n",
    "        augment = True,\n",
    "        augment_frequency = 0.5,)\n",
    "\n",
    "generator_val = Generator.Dataset_2D(\n",
    "        supervision = supervision,\n",
    "        target = target,\n",
    "\n",
    "        img_list = x0_list_val,\n",
    "        condition_list = condition_list_val,\n",
    "        image_size = image_size,\n",
    "\n",
    "        num_slices_per_image = 20,\n",
    "        random_pick_slice = False,\n",
    "        slice_range = [50,70],\n",
    "\n",
    "        num_patches_per_slice = 1,\n",
    "        patch_size = [512,512],\n",
    "\n",
    "        histogram_equalization = histogram_equalization,\n",
    "        bins = np.load('./help_data/histogram_equalization/bins.npy'),\n",
    "        bins_mapped = np.load('./help_data/histogram_equalization/bins_mapped.npy'),\n",
    "        \n",
    "        background_cutoff = background_cutoff,\n",
    "        maximum_cutoff = maximum_cutoff,\n",
    "        normalize_factor = normalize_factor,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conditional diffusion:  True\n",
      "target:  current\n"
     ]
    }
   ],
   "source": [
    "### define trainer\n",
    "results_folder = os.path.join(main_path, 'models', trial_name, 'models')\n",
    "ff.make_folder([os.path.join(main_path, 'models'), os.path.join(main_path, 'models', trial_name), results_folder, os.path.join(main_path, 'models', trial_name, 'log')])\n",
    "\n",
    "trainer = ddpm.Trainer(\n",
    "    diffusion_model= diffusion_model,\n",
    "    generator_train = generator_train,\n",
    "    generator_val = generator_val,\n",
    "    train_batch_size = 25,\n",
    "    \n",
    "    accum_iter = 1,\n",
    "    train_num_steps = 100, # total training epochs\n",
    "    results_folder = os.path.join('/mnt/camca_NAS/denoising/models', trial_name, 'models'),\n",
    "   \n",
    "    train_lr = 1e-4,\n",
    "    train_lr_decay_every = 200, \n",
    "    save_models_every = 1,\n",
    "    validation_every = 1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define pretrained model if any\n",
    "pre_trained_model = None\n",
    "start_step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "trainer.train(pre_trained_model=pre_trained_model, start_step= start_step, beta = beta)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
