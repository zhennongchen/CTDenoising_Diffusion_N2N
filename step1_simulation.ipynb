{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "You should prepare the following things before running this step. \n",
    "\n",
    "1. **NIfTI images** of fixed CT\n",
    "   - we are going to use it to simulate the noise-free ground truth and noisy thin-slice counterpart.\n",
    "\n",
    "2. **A patient list** that emunarates these fixed CT.  \n",
    "   - we have 100 fixed CT in this study.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Task: Simulate noise-free ground truth and noisy thin-slice counterpart\n",
    "\n",
    "- In this script, we start with any fixed CT scan. We first resample it to 5mm using averaging.\n",
    "\n",
    "- Then we resample this ground truth into 0.625mm using interpolation, which will be considered as **\"noise-free thin slice\"**. We select middle 100 slices, otherwise the data is too big. The file is named as ```fixedCT/img_thinslice_partial.nii.gz```\n",
    "\n",
    "- Lastly, we insert noise into thin slices (using two types of noises), which will be considered as **\"noisy thin slice\"**. The file is named as ```simulation/recon.nii.gz```\n",
    "\n",
    "---\n",
    "\n",
    "### Docker environment\n",
    "Please use `docker/docker_tensorflow`, it will build a tensorflow docker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/workspace/Documents')\n",
    "# imports\n",
    "import os, sys\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import nibabel as nb\n",
    "from skimage.measure import block_reduce\n",
    "\n",
    "import CTDenoising_Diffusion_N2N.functions_collection as ff\n",
    "import CTDenoising_Diffusion_N2N.Data_processing as Data_processing\n",
    "\n",
    "data_path = '/mnt/camca_NAS/Portable_CT_data'\n",
    "main_path = '/mnt/camca_NAS/denoising/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 1: resample all fixed CT to 5mm using averaging, then interpolate to 0.625mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read patient list\n",
    "patient_sheet = pd.read_excel(os.path.join(main_path,'Patient_lists', 'fixedCT_static.xlsx'),dtype={'Patient_ID': str, 'Patient_subID': str})\n",
    "print('patient sheet len: ', len(patient_sheet))\n",
    "\n",
    "for i in range(0, len(patient_sheet)):\n",
    "    row = patient_sheet.iloc[i]\n",
    "    patient_id = row['Patient_ID']\n",
    "    patient_subID = row['Patient_subID']\n",
    "    use = row['use']\n",
    "\n",
    "    original_file = os.path.join(data_path,'nii_imgs_202404/static',patient_id,patient_subID,'fixed', use+'.nii.gz')\n",
    "    \n",
    "    # get the affine and pixel dimension\n",
    "    img = nb.load(original_file)\n",
    "    affine = img.affine\n",
    "    pixdim = img.header.get_zooms()\n",
    "    img_data = img.get_fdata()\n",
    "\n",
    "    # define save folder\n",
    "    save_folder = os.path.join(main_path, 'Data/fixedCT', patient_id, patient_subID)\n",
    "    ff.make_folder([os.path.join(main_path,'Data/fixedCT'), os.path.join(main_path,'Data/fixedCT', patient_id), os.path.join(main_path,'Data/fixedCT', patient_id, patient_subID)])\n",
    "\n",
    "    ######### first, resample slice thickness to 5mm using averaging\n",
    "    z_scale_factor = int(5 // pixdim[2])\n",
    "    print('z_scale_factor: ', z_scale_factor)\n",
    "    img_data_xyz5mm = block_reduce(img_data, (1,1,z_scale_factor), np.mean)\n",
    "\n",
    "    # change affine and pixel dimension accordingly\n",
    "    new_affine_5mm = affine.copy()\n",
    "    new_affine_5mm[2, 2] *= z_scale_factor\n",
    "    new_pixdim_5mm = (pixdim[0],pixdim[1], pixdim[2]*z_scale_factor)\n",
    "    # save in the header\n",
    "    img.header.set_zooms(new_pixdim_5mm)\n",
    "\n",
    "    # save the image\n",
    "    save_file = os.path.join(save_folder, 'img_5mm.nii.gz')\n",
    "    nb.save(nb.Nifti1Image(img_data_xyz5mm, new_affine_5mm, img.header), save_file)\n",
    "\n",
    "    ######### second, resample slice thickness to 0.625mm using interpolation\n",
    "    new_dim = [pixdim[0], pixdim[1], 0.625]\n",
    "\n",
    "    img_5mm = nb.load(os.path.join(save_folder, 'img_5mm.nii.gz'))\n",
    "    hr_resample = Data_processing.resample_nifti(img_5mm, order=1,  mode = 'nearest',  cval = np.min(img_5mm.get_fdata()), in_plane_resolution_mm=new_dim[0], slice_thickness_mm=new_dim[-1])\n",
    "    nb.save(hr_resample, os.path.join(save_folder, 'img_thinslice.nii.gz'))\n",
    "\n",
    "    ######### select middle 100 slices\n",
    "    img_thinslice = nb.load(os.path.join(save_folder, 'img_thinslice.nii.gz'))\n",
    "    img_thinslice_data = img_thinslice.get_fdata()[:,:,img_thinslice.shape[2]//2-50:img_thinslice.shape[2]//2+50]\n",
    "    nb.save(nb.Nifti1Image(img_thinslice_data, img_thinslice.affine, img_thinslice.header), os.path.join(save_folder, 'img_thinslice_partial.nii.gz'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 2: insert two types of noise\n",
    "- type 1: Poisson noise + hann filter\n",
    "- type 2: Gaussian noise + soft tissue kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nibabel as nb \n",
    "import pandas as pd\n",
    "import os\n",
    "import copy\n",
    "import CTDenoising_Diffusion_N2N.simulation.ct_basic_PCD as ct\n",
    "import CTDenoising_Diffusion_N2N.functions_collection as ff\n",
    "import ct_projector.projector.numpy.parallel as ct_para\n",
    "\n",
    "main_path = '/mnt/camca_NAS/denoising/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient sheet len:  100\n",
      "00214938 0000455723\n",
      "dose factor:  0.15158064184329842\n",
      "img shape, min, max:  (100, 512, 512) -1023.99994 1515.9093\n",
      "spacing:  (0.625, 0.48046875, 0.48046875)\n",
      "dose factor:  0.10827024880920996\n",
      "img shape, min, max:  (100, 512, 512) -1023.99994 1515.9093\n",
      "spacing:  (0.625, 0.48046875, 0.48046875)\n",
      "dose factor:  0.22180748949719348\n",
      "img shape, min, max:  (100, 512, 512) -1023.99994 1515.9093\n",
      "spacing:  (0.625, 0.48046875, 0.48046875)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/workspace/Documents/CTDenoising_Diffusion_N2N/step1_simulation.ipynb Cell 7\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f646f636b65725f6578227d@ssh-remote%2B7b22686f73744e616d65223a227a68656e6e6f6e676368656e5f434344535f47505533227d/workspace/Documents/CTDenoising_Diffusion_N2N/step1_simulation.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=59'>60</a>\u001b[0m img_slice \u001b[39m=\u001b[39m (img_slice[np\u001b[39m.\u001b[39mnewaxis, \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m] \u001b[39m+\u001b[39m \u001b[39m1000\u001b[39m) \u001b[39m/\u001b[39m \u001b[39m1000\u001b[39m \u001b[39m*\u001b[39m \u001b[39m0.019\u001b[39m \n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f646f636b65725f6578227d@ssh-remote%2B7b22686f73744e616d65223a227a68656e6e6f6e676368656e5f434344535f47505533227d/workspace/Documents/CTDenoising_Diffusion_N2N/step1_simulation.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=61'>62</a>\u001b[0m prjs \u001b[39m=\u001b[39m ct_para\u001b[39m.\u001b[39mdistance_driven_fp(projector, img_slice, angles)\n\u001b[0;32m---> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f646f636b65725f6578227d@ssh-remote%2B7b22686f73744e616d65223a227a68656e6e6f6e676368656e5f434344535f47505533227d/workspace/Documents/CTDenoising_Diffusion_N2N/step1_simulation.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=62'>63</a>\u001b[0m fprjs \u001b[39m=\u001b[39m ct_para\u001b[39m.\u001b[39;49mramp_filter(projector, prjs, \u001b[39m'\u001b[39;49m\u001b[39mrl\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f646f636b65725f6578227d@ssh-remote%2B7b22686f73744e616d65223a227a68656e6e6f6e676368656e5f434344535f47505533227d/workspace/Documents/CTDenoising_Diffusion_N2N/step1_simulation.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=64'>65</a>\u001b[0m \u001b[39m# add noise\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f646f636b65725f6578227d@ssh-remote%2B7b22686f73744e616d65223a227a68656e6e6f6e676368656e5f434344535f47505533227d/workspace/Documents/CTDenoising_Diffusion_N2N/step1_simulation.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=65'>66</a>\u001b[0m \u001b[39mif\u001b[39;00m noise_type[\u001b[39m0\u001b[39m:\u001b[39m2\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mpo\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f646f636b65725f6578227d@ssh-remote%2B7b22686f73744e616d65223a227a68656e6e6f6e676368656e5f434344535f47505533227d/workspace/Documents/CTDenoising_Diffusion_N2N/step1_simulation.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=66'>67</a>\u001b[0m     \u001b[39m# add poisson noise\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/ct_projector/projector/numpy/parallel.py:54\u001b[0m, in \u001b[0;36mramp_filter\u001b[0;34m(projector, prj, filter_type)\u001b[0m\n\u001b[1;32m     50\u001b[0m fprj \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros(prj\u001b[39m.\u001b[39mshape, np\u001b[39m.\u001b[39mfloat32)\n\u001b[1;32m     52\u001b[0m module\u001b[39m.\u001b[39mcfbpParallelFilter\u001b[39m.\u001b[39mrestype \u001b[39m=\u001b[39m c_int\n\u001b[0;32m---> 54\u001b[0m err \u001b[39m=\u001b[39m module\u001b[39m.\u001b[39;49mcfbpParallelFilter(\n\u001b[1;32m     55\u001b[0m     fprj\u001b[39m.\u001b[39;49mctypes\u001b[39m.\u001b[39;49mdata_as(POINTER(c_float)),\n\u001b[1;32m     56\u001b[0m     prj\u001b[39m.\u001b[39;49mctypes\u001b[39m.\u001b[39;49mdata_as(POINTER(c_float)),\n\u001b[1;32m     57\u001b[0m     c_ulong(prj\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39;49m]),\n\u001b[1;32m     58\u001b[0m     c_ulong(prj\u001b[39m.\u001b[39;49mshape[\u001b[39m3\u001b[39;49m]),\n\u001b[1;32m     59\u001b[0m     c_ulong(prj\u001b[39m.\u001b[39;49mshape[\u001b[39m2\u001b[39;49m]),\n\u001b[1;32m     60\u001b[0m     c_ulong(prj\u001b[39m.\u001b[39;49mshape[\u001b[39m1\u001b[39;49m]),\n\u001b[1;32m     61\u001b[0m     c_float(projector\u001b[39m.\u001b[39;49mdu),\n\u001b[1;32m     62\u001b[0m     c_float(projector\u001b[39m.\u001b[39;49mdv),\n\u001b[1;32m     63\u001b[0m     c_float(projector\u001b[39m.\u001b[39;49moff_u),\n\u001b[1;32m     64\u001b[0m     c_float(projector\u001b[39m.\u001b[39;49moff_v),\n\u001b[1;32m     65\u001b[0m     c_int(ifilter)\n\u001b[1;32m     66\u001b[0m )\n\u001b[1;32m     68\u001b[0m \u001b[39mif\u001b[39;00m err \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     69\u001b[0m     \u001b[39mprint\u001b[39m(err)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# define the patient list\n",
    "patient_sheet = pd.read_excel(os.path.join(main_path,'Patient_lists', 'fixedCT_static.xlsx'),dtype={'Patient_ID': str, 'Patient_subID': str})\n",
    "print('patient sheet len: ', len(patient_sheet))\n",
    "\n",
    "\n",
    "simulation_num = 2\n",
    "# do noise insertion, noise type = 'possion' (type1) or 'gaussian'(type2)\n",
    "for i in range(0,len(patient_sheet)):\n",
    "    row = patient_sheet.iloc[i]\n",
    "    patient_id = row['Patient_ID']\n",
    "    patient_subID = row['Patient_subID']\n",
    "\n",
    "    print(patient_id, patient_subID)\n",
    "\n",
    "    save_folder_case = os.path.join(main_path,'Data','simulation', patient_id,patient_subID)\n",
    "    ff.make_folder([os.path.join(main_path,'Data','simulation'), os.path.join(main_path,'Data','simulation', patient_id), os.path.join(main_path,'Data','simulation', patient_id, patient_subID)])\n",
    "\n",
    "\n",
    "    # noise-free thin-slice img file\n",
    "    img_file = os.path.join(main_path,'Data/fixedCT',patient_id,patient_subID,'img_thinslice_partial.nii.gz')\n",
    "    # load img\n",
    "    img_clean = nb.load(img_file).get_fdata().astype(np.float32)\n",
    "    img_clean[img_clean < -1024] = -1024\n",
    "    spacing = nb.load(img_file).header.get_zooms()[::-1]\n",
    "    affine = nb.load(img_file).affine\n",
    "\n",
    "    for noise_type in ['possion', 'gaussian']: # two types\n",
    "        #  we decided the following dose range by default\n",
    "        possion_hann_dose_range = [0.10,0.20]\n",
    "        gaussian_custom_dose_range = [0.15,0.25]\n",
    "        \n",
    "        for k in range(0,simulation_num):\n",
    "            save_folder_k = os.path.join(save_folder_case, noise_type+'_random_'+str(k));ff.make_folder([save_folder_k])\n",
    "            if os.path.isfile(os.path.join(save_folder_k,'recon.nii.gz')):\n",
    "                print('already done, continue')\n",
    "                continue\n",
    "\n",
    "            if noise_type == 'possion':\n",
    "                dose_factor = np.random.uniform(possion_hann_dose_range[0],possion_hann_dose_range[1] + 1e-8)\n",
    "            elif noise_type == 'gaussian':\n",
    "                dose_factor = np.random.uniform(gaussian_custom_dose_range[0],gaussian_custom_dose_range[1] + 1e-8)\n",
    "            print('dose factor: ', dose_factor)\n",
    "\n",
    "            # process img\n",
    "            img0 = img_clean.copy()\n",
    "            img0 = np.rollaxis(img0,-1,0)\n",
    "            print('img shape, min, max: ', img0.shape, np.min(img0), np.max(img0))\n",
    "            print('spacing: ', spacing)\n",
    "      \n",
    "            # define projectors\n",
    "            projector = ct.define_forward_projector_pcd(img0,spacing, file_name = './help_data/pcd_parallel_6x5_512.cfg')\n",
    "\n",
    "            # set angles\n",
    "            angles = projector.get_angles()\n",
    "\n",
    "            # recon\n",
    "            recon_noise = np.zeros((img0.shape[1], img0.shape[2], img0.shape[0]), np.float32)\n",
    "            for slice_n in range(0, img0.shape[0]):\n",
    "                img_slice = img0[[slice_n],:,:].copy()\n",
    "                img_slice = (img_slice[np.newaxis, ...] + 1000) / 1000 * 0.019 \n",
    "\n",
    "                prjs = ct_para.distance_driven_fp(projector, img_slice, angles)\n",
    "                fprjs = ct_para.ramp_filter(projector, prjs, 'rl')\n",
    "\n",
    "                # add noise\n",
    "                if noise_type[0:2] == 'po':\n",
    "                    # add poisson noise\n",
    "                    noise_of_prjs = ct.add_poisson_noise(prjs, N0=1000000, dose_factor = dose_factor) - prjs\n",
    "                elif noise_type[0:2] == 'ga':\n",
    "                    # add gaussian noise\n",
    "                    noise_of_prjs = ct.add_gaussian_noise(prjs, N0=1000000, dose_factor = dose_factor) - prjs\n",
    "\n",
    "                # recon\n",
    "                if noise_type[0:2] == 'po':\n",
    "                    # hann filter\n",
    "                    fnoise = ct_para.ramp_filter(projector, noise_of_prjs, 'hann')\n",
    "                    recon_hann = ct_para.distance_driven_bp(projector, fnoise, angles, True) + img_slice\n",
    "                    recon_hann = recon_hann[0, 0] / 0.019 * 1000 - 1000\n",
    "                    recon_noise[:,:,slice_n] = recon_hann\n",
    "                \n",
    "                elif noise_type[0:2] == 'ga':\n",
    "                    # custom filter\n",
    "                    soft_tissue_kernel_file = './help_data/softTissueKernel_65'\n",
    "                    custom_additional_filter = ct.get_additional_filter_to_rl(soft_tissue_kernel_file, projector.nu, projector.du, projector.nview)\n",
    "                    recon_custom = ct.interleave_filter_and_recon(projector, noise_of_prjs, custom_additional_filter,angles) + img_slice\n",
    "                    recon_custom = recon_custom[0, 0] / 0.019 * 1000 - 1000\n",
    "                    recon_noise[:,:,slice_n] = recon_custom\n",
    "            \n",
    "            # save recon\n",
    "            nb.save(nb.Nifti1Image(recon_noise, affine), os.path.join(save_folder_k,'recon.nii.gz'))\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
