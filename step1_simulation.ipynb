{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "You should prepare the following things before running this step. \n",
    "\n",
    "1. **NIfTI images** of fixed CT\n",
    "   - we are going to use it to simulate the noise-free ground truth and noisy thin-slice counterpart.\n",
    "\n",
    "2. **A patient list** that emunarates these fixed CT.  \n",
    "   - we have 100 fixed CT in this study.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Task: Simulate noise-free ground truth and noisy thin-slice counterpart\n",
    "\n",
    "- In this script, we start with any fixed CT scan. We first resample it to 5mm using averaging, which will be considered as **\"noise-free ground truth\"**. \n",
    "\n",
    "- Then we resample this ground truth into 0.625mm using interpolation, which will be considered as **\"noise-free thin slice\"**. We select middle 100 slices, otherwise the data is too big. The file is named as ```img_thinslice_partial.nii.gz```\n",
    "\n",
    "- Lastly, we insert noise into thin slices (using two types of noises), which will be considered as **\"noisy thin slice\"**.\n",
    "\n",
    "---\n",
    "\n",
    "### Docker environment\n",
    "Please use `docker/docker_tensorflow`, it will build a tensorflow docker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/workspace/Documents')\n",
    "# imports\n",
    "import os, sys\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import nibabel as nb\n",
    "from skimage.measure import block_reduce\n",
    "\n",
    "import CTDenoising_Diffusion_N2N.functions_collection as ff\n",
    "import CTDenoising_Diffusion_N2N.Data_processing as Data_processing\n",
    "\n",
    "data_path = '/mnt/camca_NAS/Portable_CT_data'\n",
    "main_path = '/mnt/camca_NAS/denoising/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 1: resample all fixed CT to 5mm using averaging, then interpolate to 0.625mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read patient list\n",
    "patient_sheet = pd.read_excel(os.path.join(main_path,'Patient_lists', 'fixedCT_static.xlsx'),dtype={'Patient_ID': str, 'Patient_subID': str})\n",
    "print('patient sheet len: ', len(patient_sheet))\n",
    "\n",
    "for i in range(0, len(patient_sheet)):\n",
    "    row = patient_sheet.iloc[i]\n",
    "    patient_id = row['Patient_ID']\n",
    "    patient_subID = row['Patient_subID']\n",
    "    use = row['use']\n",
    "\n",
    "    original_file = os.path.join(data_path,'nii_imgs_202404/static',patient_id,patient_subID,'fixed', use+'.nii.gz')\n",
    "    \n",
    "    # get the affine and pixel dimension\n",
    "    img = nb.load(original_file)\n",
    "    affine = img.affine\n",
    "    pixdim = img.header.get_zooms()\n",
    "    img_data = img.get_fdata()\n",
    "\n",
    "    # define save folder\n",
    "    save_folder = os.path.join(main_path, 'Data/fixedCT1', patient_id, patient_subID)\n",
    "    ff.make_folder([os.path.join(main_path,'Data/fixedCT1'), os.path.join(main_path,'Data/fixedCT1', patient_id), os.path.join(main_path,'Data/fixedCT1', patient_id, patient_subID)])\n",
    "\n",
    "    ######### first, resample slice thickness to 5mm using averaging\n",
    "    z_scale_factor = int(5 // pixdim[2])\n",
    "    print('z_scale_factor: ', z_scale_factor)\n",
    "    img_data_xyz5mm = block_reduce(img_data, (1,1,z_scale_factor), np.mean)\n",
    "\n",
    "    # change affine and pixel dimension accordingly\n",
    "    new_affine_5mm = affine.copy()\n",
    "    new_affine_5mm[2, 2] *= z_scale_factor\n",
    "    new_pixdim_5mm = (pixdim[0],pixdim[1], pixdim[2]*z_scale_factor)\n",
    "    # save in the header\n",
    "    img.header.set_zooms(new_pixdim_5mm)\n",
    "\n",
    "    # save the image\n",
    "    save_file = os.path.join(save_folder, 'img_5mm.nii.gz')\n",
    "    nb.save(nb.Nifti1Image(img_data_xyz5mm, new_affine_5mm, img.header), save_file)\n",
    "\n",
    "    ######### second, resample slice thickness to 0.625mm using interpolation\n",
    "    new_dim = [pixdim[0], pixdim[1], 0.625]\n",
    "\n",
    "    img_5mm = nb.load(os.path.join(save_folder, 'img_5mm.nii.gz'))\n",
    "    hr_resample = Data_processing.resample_nifti(img_5mm, order=1,  mode = 'nearest',  cval = np.min(img_5mm.get_fdata()), in_plane_resolution_mm=new_dim[0], slice_thickness_mm=new_dim[-1])\n",
    "    nb.save(hr_resample, os.path.join(save_folder, 'img_thinslice.nii.gz'))\n",
    "\n",
    "    ######### select middle 100 slices\n",
    "    img_thinslice = nb.load(os.path.join(save_folder, 'img_thinslice.nii.gz'))\n",
    "    img_thinslice_data = img_thinslice.get_fdata()[:,:,img_thinslice.shape[2]//2-50:img_thinslice.shape[2]//2+50]\n",
    "    nb.save(nb.Nifti1Image(img_thinslice_data, img_thinslice.affine, img_thinslice.header), os.path.join(save_folder, 'img_thinslice_partial.nii.gz'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 2: insert two types of noise\n",
    "- type 1: Possion noise + hann filter\n",
    "- type 2: Gaussian noise + soft tissue kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
