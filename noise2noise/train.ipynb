{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'''use two adajacent noisy slices as input, use current noisy slice as output reference'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure you have Github copilot installed, search it in the VSCode extension marketplace, it will make your coding much easier\n",
    "import sys \n",
    "sys.path.append('/host/d/Github/')\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import CTDenoising_Diffusion_N2N.noise2noise.model as noise2noise\n",
    "import CTDenoising_Diffusion_N2N.functions_collection as ff\n",
    "import CTDenoising_Diffusion_N2N.Build_lists.Build_list as Build_list\n",
    "import CTDenoising_Diffusion_N2N.noise2noise.Generator as Generator\n",
    "\n",
    "# if it says no module named ... (e.g., lpips), do the following:\n",
    "# 1. go to powershell, type wsl, enter wsl\n",
    "# 2. in wsl, type: sudo docker container ls, you will see the container id of your running container\n",
    "# 3. type: sudo docker container exec -it -u 0 <container_id> bash\n",
    "# 4. now you are inside the container root, type: pip install lpips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 1: define trial name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_name = 'noise2noise'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 2: define parameters (no need to change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = [512,512]\n",
    "num_patches_per_slice = 2\n",
    "patch_size = [128,128]\n",
    "\n",
    "histogram_equalization = True\n",
    "background_cutoff = -1000\n",
    "maximum_cutoff = 2000\n",
    "normalize_factor = 'equation'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 3: build patient list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (1,) (1,) val: (1,) (1,)\n",
      "['/host/d/Github/CTDenoising_Diffusion_N2N/example_data/fixedCT/00004038/0000455420/img_thinslice_partial.nii.gz'] ['/host/d/Github/CTDenoising_Diffusion_N2N/example_data/simulation/00004038/0000455420/poisson_random_0/recon.nii.gz'] ['/host/d/Github/CTDenoising_Diffusion_N2N/example_data/fixedCT/00004038/0000455420/img_thinslice_partial.nii.gz'] ['/host/d/Github/CTDenoising_Diffusion_N2N/example_data/simulation/00004038/0000455420/poisson_random_0/recon.nii.gz']\n"
     ]
    }
   ],
   "source": [
    "# change the excel path to your own path\n",
    "# example excel path (you can find it in this repo - example data folder)\n",
    "# build_sheet =  Build_list.Build(os.path.join('/host/d/Github/CTDenoising_Diffusion_N2N/example_data/patient_lists/patient_list_supervised.xlsx'))\n",
    "# use the spreadsheet I gave to you and put the path here:\n",
    "build_sheet =  Build_list.Build(os.path.join('/host/d/projects/denoising/Patient_lists/fixedCT_static_simulation_train_test_gaussian_local.xlsx'))\n",
    "\n",
    "_,_,_,_, condition_list_train, x0_list_train = build_sheet.__build__(batch_list = [0,1,2,3])\n",
    " \n",
    "# define val\n",
    "_,_,_,_, condition_list_val, x0_list_val = build_sheet.__build__(batch_list = [4])\n",
    "\n",
    "print('train:', x0_list_train.shape, condition_list_train.shape, 'val:', x0_list_val.shape, condition_list_val.shape)\n",
    "print(x0_list_train[0:5], condition_list_train[0:5], x0_list_val[0:5], condition_list_val[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in out is :  [(16, 32), (32, 64), (64, 128), (128, 256)]\n"
     ]
    }
   ],
   "source": [
    "# build model\n",
    "model = noise2noise.Unet2D(\n",
    "    init_dim = 16,\n",
    "    channels = 2, \n",
    "    out_dim = 1,\n",
    "    dim_mults = (2,4,8,16),\n",
    "    full_attn = (None,None, False, True),\n",
    "    act = 'ReLU',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load histogram equalization pre-saved files\n",
    "# change to your own path, they are in this repo - example data folder\n",
    "bins = np.load('/host/d/Github/CTDenoising_Diffusion_N2N/example_data/histogram_equalization/bins.npy') \n",
    "bins_mapped = np.load('/host/d/Github/CTDenoising_Diffusion_N2N/example_data/histogram_equalization/bins_mapped.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_train = Generator.Dataset_2D(\n",
    "        img_list = condition_list_train, \n",
    "        image_size = image_size,\n",
    "\n",
    "        num_slices_per_image = 50,\n",
    "        random_pick_slice = True,\n",
    "        slice_range = None,\n",
    "\n",
    "        num_patches_per_slice = num_patches_per_slice,\n",
    "        patch_size = patch_size, # train on patches to save GPU memory\n",
    "\n",
    "        bins = bins,\n",
    "        bins_mapped = bins_mapped,\n",
    "        histogram_equalization = histogram_equalization,\n",
    "        background_cutoff = background_cutoff,\n",
    "        maximum_cutoff = maximum_cutoff,\n",
    "        normalize_factor = normalize_factor,\n",
    "\n",
    "        shuffle = True,\n",
    "        augment = True,\n",
    "        augment_frequency = 0.5,)\n",
    "\n",
    "generator_val = Generator.Dataset_2D(\n",
    "        img_list = condition_list_val,\n",
    "        image_size = image_size,\n",
    "\n",
    "        num_slices_per_image = 20,\n",
    "        random_pick_slice = False,\n",
    "        slice_range = [50,70],\n",
    "\n",
    "        num_patches_per_slice = 1,\n",
    "        patch_size = [512,512], # validate on full image\n",
    "\n",
    "        bins = bins,\n",
    "        bins_mapped = bins_mapped,\n",
    "        histogram_equalization = histogram_equalization,\n",
    "        background_cutoff = background_cutoff,\n",
    "        maximum_cutoff = maximum_cutoff,\n",
    "        normalize_factor = normalize_factor,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 6: train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### define pretrained model path if any\n",
    "pre_trained_model = None\n",
    "start_step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "# first define a path to save your model\n",
    "model_save_path = os.path.join('/host/d/projects/denoising/models', trial_name,'models')\n",
    "ff.make_folder([os.path.dirname(model_save_path), model_save_path])\n",
    "\n",
    "trainer = noise2noise.Trainer(\n",
    "    model= model,\n",
    "    generator_train = generator_train,\n",
    "    generator_val = generator_val,\n",
    "    train_batch_size = 25,\n",
    "\n",
    "    train_num_steps = 10000, # total training epochs\n",
    "    results_folder = model_save_path,\n",
    "   \n",
    "    train_lr = 1e-4,\n",
    "    train_lr_decay_every = 200, # define learning rate decay schedule\n",
    "    save_models_every = 1, # save model frequency (in epochs)\n",
    "    validation_every = 1, # validation frequency (in epochs)\n",
    ")\n",
    "\n",
    "trainer.train(pre_trained_model=pre_trained_model, start_step= start_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
